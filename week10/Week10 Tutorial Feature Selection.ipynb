{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Feature selection is also known as Variable selection or Attribute selection. Essentially, it is the process of selecting the most important/relevant features of a dataset. \n",
    "\n",
    "The importance of feature selection can best be recognized when you are dealing with a dataset that contains a vast number of features. This type of dataset is often referred to as a high dimensional dataset. Now, with this high dimensionality, comes a lot of problems such as - this high dimensionality will significantly increase the training time of your machine learning model, it can make your model very complicated which in turn may lead to Overfitting.\n",
    "\n",
    "Often in a high dimensional feature set, there remain several features which are redundant meaning these features are nothing but extensions of the other essential features. These redundant features do not effectively contribute to the model training as well. So, clearly, there is a need to extract the most important and the most relevant features for a dataset in order to get the most effective predictive modeling performance.\n",
    "\n",
    "Let me summarize the importance of feature selection:\n",
    "\n",
    "- It enables the machine learning algorithm to train faster.\n",
    "- It reduces the complexity of a model and makes it easier to interpret.\n",
    "- It improves the accuracy of a model if the right subset is chosen.\n",
    "- It reduces Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Methods\n",
    "In this section, you will study the different types of general feature selection methods \n",
    "\n",
    "- Filter methods\n",
    "- Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods\n",
    "\n",
    "The filter method uses the principal criteria of ranking technique and uses the rank ordering method for feature selection. The reason for using the ranking method is simplicity, produce excellent and relevant features. The ranking method will filter out irrelevant features before classification process starts.\n",
    "\n",
    "Filter methods are generally used as a data preprocessing step. The selection of features is independent of any machine learning algorithm. Features give rank on the basis of statistical scores which tend to determine the features' correlation with the outcome variable. Some examples of some filter methods include the Chi-squared test and correlation coefficient scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example on Python code\n",
    "\n",
    "For this example, we will use the Pima Indians Diabetes dataset. The description of the dataset can be found here. https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "The dataset corresponds to classification tasks on which you need to predict if a person has diabetes based on 8 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "diabetes_dataset = pd.read_csv(\"diabetes.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries first\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "X = diabetes_dataset[feature_columns] # Features\n",
    "y = diabetes_dataset.Outcome # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared statistical test\n",
    "\n",
    "Chi-squared stats of non-negative features for classification tasks. See more details on https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2\n",
    "\n",
    "We now implement a Chi-Squared statistical test for non-negative features to select 4 of the best features from the dataset. You have already seen Chi-Squared test belongs the class of filter methods. If anyone's curious about knowing the internals of Chi-Squared, see the video here https://www.youtube.com/watch?v=VskmMgXmkMQ.\n",
    "\n",
    "The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features, in this case, it is Chi-Squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=3, score_func=<function chi2 at 0x000001CDC9EACE50>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features  = SelectKBest(score_func=chi2, k=3)\n",
    "best_features.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.51969064 1411.88704064   17.60537322   53.10803984 2175.56527292\n",
      "  127.66934333    5.39268155  181.30368904]\n"
     ]
    }
   ],
   "source": [
    "print(best_features.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.   0.  50.]\n",
      " [ 85.   0.  31.]\n",
      " [183.   0.  32.]\n",
      " [ 89.  94.  21.]\n",
      " [137. 168.  33.]]\n"
     ]
    }
   ],
   "source": [
    "features = best_features.transform(X)\n",
    "# Summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print features and their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Features  Schi-square Score\n",
      "4                   Insulin        2175.565273\n",
      "1                   Glucose        1411.887041\n",
      "7                       Age         181.303689\n",
      "5                       BMI         127.669343\n",
      "0               Pregnancies         111.519691\n",
      "3             SkinThickness          53.108040\n",
      "2             BloodPressure          17.605373\n",
      "6  DiabetesPedigreeFunction           5.392682\n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concatenate dataframes\n",
    "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
    "feature_scores.columns = ['Features','Schi-square Score']  \n",
    "print(feature_scores.nlargest(8,'Schi-square Score'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "You can see the scores for each attribute and the 3 attributes chosen (those with the highest scores): \n",
    "\n",
    "- Insulin \n",
    "- Glucose\n",
    "- Age \n",
    "\n",
    "This scores will help you further in determining the best features for training your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods\n",
    "\n",
    "A wrapper method needs one machine learning algorithm and uses its performance as evaluation criteria. This method searches for a feature which is best-suited for the machine learning algorithm and aims to improve the performance. To evaluate the features, the predictive accuracy used for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Feature Elimination**\n",
    "\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
    "\n",
    "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
    "\n",
    "You can learn more about the RFE class in here https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html.\n",
    "\n",
    "## An example on Python code\n",
    "\n",
    "In this example, we will continue to work with the diabetes dataset and a classification model to select features based on the RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "#reason: these models has feature importances\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter = 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier is  Decision Tree\n",
      "Accuracy: 0.7207792207792207\n",
      "F1-score: 0.7193073202985346\n",
      "--------------------------------\n",
      "classifier is  Random Forest\n",
      "Accuracy: 0.7402597402597403\n",
      "F1-score: 0.7347282347282348\n",
      "--------------------------------\n",
      "classifier is  Logistic Regression\n",
      "Accuracy: 0.7077922077922078\n",
      "F1-score: 0.7007679166976141\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifiers.items():    \n",
    "    print(\"classifier is \", name)\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if (best_model_score < metrics.accuracy_score(y_test, y_pred)):\n",
    "        best_model = classifier\n",
    "        best_model_score = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#    print(\"Precision:\",metrics.precision_score(y_test, y_pred, average = 'weighted'))\n",
    "#    print(\"Recall:\",metrics.recall_score(y_test, y_pred, average = 'weighted'))\n",
    "    print(\"F1-score:\",metrics.f1_score(y_test, y_pred, average = 'weighted'))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the RFE method\n",
    "\n",
    "You will use RFE with the various classifiers to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features is  1\n",
      "Accuracy: 0.6493506493506493\n",
      "F1-score: 0.6273661480029404\n",
      "--------------------------------\n",
      "Number of features is  2\n",
      "Accuracy: 0.6558441558441559\n",
      "F1-score: 0.641012548459815\n",
      "--------------------------------\n",
      "Number of features is  3\n",
      "Accuracy: 0.7012987012987013\n",
      "F1-score: 0.6894711988943857\n",
      "--------------------------------\n",
      "Number of features is  4\n",
      "Accuracy: 0.7012987012987013\n",
      "F1-score: 0.6949374699374701\n",
      "--------------------------------\n",
      "Number of features is  5\n",
      "Accuracy: 0.7207792207792207\n",
      "F1-score: 0.7124346917450366\n",
      "--------------------------------\n",
      "Number of features is  6\n",
      "Accuracy: 0.7402597402597403\n",
      "F1-score: 0.7332725186265256\n",
      "--------------------------------\n",
      "Number of features is  7\n",
      "Accuracy: 0.7337662337662337\n",
      "F1-score: 0.7287952930385277\n",
      "--------------------------------\n",
      "Number of features is  8\n",
      "Accuracy: 0.7207792207792207\n",
      "F1-score: 0.7124346917450366\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n_features in range(1, 9, 1):    \n",
    "    print(\"Number of features is \", n_features)\n",
    "    \n",
    "    rfe = RFE(best_model, n_features_to_select=n_features)\n",
    "    model = rfe.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if (best_model_score < metrics.f1_score(y_test, y_pred, average = 'weighted')):\n",
    "        n_best_features = n_features\n",
    "        rfe_best = rfe\n",
    "        best_model_score = metrics.f1_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#    print(\"Precision:\",metrics.precision_score(y_test, y_pred, average = 'weighted'))\n",
    "#    print(\"Recall:\",metrics.recall_score(y_test, y_pred, average = 'weighted'))\n",
    "    print(\"F1-score:\",metrics.f1_score(y_test, y_pred, average = 'weighted'))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(), n_features_to_select=6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 6\n",
      "Selected Features: [ True  True  True False False  True  True  True]\n",
      "Feature Ranking: [1 1 1 3 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Features: %s\" % (rfe_best.n_features_))\n",
    "print(\"Selected Features: %s\" % (rfe_best.support_))\n",
    "print(\"Feature Ranking: %s\" % (rfe_best.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Features  Ranking\n",
      "0               Pregnancies        1\n",
      "1                   Glucose        1\n",
      "2             BloodPressure        1\n",
      "5                       BMI        1\n",
      "6  DiabetesPedigreeFunction        1\n",
      "7                       Age        1\n",
      "4                   Insulin        2\n",
      "3             SkinThickness        3\n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(rfe_best.ranking_)\n",
    "df_columns = pd.DataFrame(X.columns)\n",
    "\n",
    "# concatenate dataframes\n",
    "feature_scores = pd.concat([df_columns, df_scores],axis=1)\n",
    "feature_scores.columns = ['Features','Ranking']  \n",
    "print(feature_scores.nsmallest(8,'Ranking'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are marked True in the support array and marked with a choice “1” in the ranking array. This, in turn, indicates the strength of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
